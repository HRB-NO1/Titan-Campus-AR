{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HRB-NO1/Titan-Campus-AR/blob/main/Lab1_Understanding_Feedforward_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Understanding Feedforward Neural Network</b>"
      ],
      "metadata": {
        "id": "be6QWnmo_90p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, you are required to build 3 Feedforward Neural Networks to simulate function\n",
        "<br> $y = xsin( \\frac {x^2} {300})$\n",
        "<br> in range x: +-100\n",
        "<br> You need to have a different structure for each model you build."
      ],
      "metadata": {
        "id": "q17Fv-S-AFPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements"
      ],
      "metadata": {
        "id": "5qw2_zjxqTnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 You are required to finish each part below following instructions.\n",
        "<br>2 You may work on native py files, but your work needs to include same documentation. You may use pytorch or tensorflow keras.\n",
        "<br>3 You may work in a group of 2.\n",
        "\n",
        "<br><b>For submission, submit a link to your github repo</b>\n",
        "<br>Each student in the group must all submit."
      ],
      "metadata": {
        "id": "3aQW7EXPFs5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1 data preparation\n",
        "\n",
        "In the cell below, generate training data for your model.\n",
        "<br> Generate a decent amount of training data in the interval of x.\n",
        "<br>\n",
        "<br>All data need to be separated by the same distance.\n"
      ],
      "metadata": {
        "id": "QxFzMiVTFpYq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YJs8FWjw9TC8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def function_to_simulate(x):\n",
        "    return x * np.sin(x**2 / 300)\n",
        "\n",
        "x_values = np.linspace(-100, 100, 2000)\n",
        "y_values = function_to_simulate(x_values)\n",
        "\n",
        "X = x_values.reshape(-1, 1)\n",
        "Y = y_values.reshape(-1, 1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.6, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2 build models\n",
        "\n",
        "In the cells below, build your models and train it with data from part1.\n",
        "<br>You need to split your training data to two parts. With 40% used in training, and 60% used in test.\n",
        "\n",
        "<br>You may do this with sklearn's train_test_split() or keras' validation_split together with train_test_split()."
      ],
      "metadata": {
        "id": "zgCswSdCJGNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 1\n",
        "model_1 = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(1,)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_1.compile(optimizer='adam', loss='mse')\n",
        "model_1.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "nT4G0XhGJHXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075abd20-42a8-4f5f-8235-93b5ae8396cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 1710.8030 - val_loss: 1579.8352\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1693.1537 - val_loss: 1567.6257\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1691.1998 - val_loss: 1606.1204\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.2180 - val_loss: 1582.7046\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1686.5911 - val_loss: 1582.5635\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.8314 - val_loss: 1585.3464\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.6052 - val_loss: 1577.1976\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1694.0709 - val_loss: 1578.7766\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1688.7429 - val_loss: 1599.5402\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.3367 - val_loss: 1577.2460\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1688.5336 - val_loss: 1576.4678\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1683.0709 - val_loss: 1591.0566\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1691.6213 - val_loss: 1581.5208\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.7229 - val_loss: 1589.7483\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.6213 - val_loss: 1580.1560\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.9313 - val_loss: 1577.6614\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1687.4941 - val_loss: 1593.5300\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.6892 - val_loss: 1580.2634\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.3711 - val_loss: 1582.8906\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1694.7448 - val_loss: 1600.6809\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1686.6902 - val_loss: 1591.2616\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.8959 - val_loss: 1576.2629\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.0457 - val_loss: 1579.1416\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1696.1145 - val_loss: 1585.5923\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.4629 - val_loss: 1593.0394\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1687.3724 - val_loss: 1581.4539\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1690.1451 - val_loss: 1593.3162\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1688.1895 - val_loss: 1576.5339\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1686.3805 - val_loss: 1598.3821\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1689.7982 - val_loss: 1573.4371\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.8088 - val_loss: 1583.0447\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.3679 - val_loss: 1583.6665\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1692.2451 - val_loss: 1586.7308\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.5846 - val_loss: 1575.3729\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1688.6318 - val_loss: 1584.2007\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1690.6155 - val_loss: 1586.4197\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1691.9359 - val_loss: 1587.2377\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.1891 - val_loss: 1581.8162\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.2272 - val_loss: 1577.1147\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.6156 - val_loss: 1588.5267\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1689.4584 - val_loss: 1584.1780\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1691.1553 - val_loss: 1579.5795\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.8262 - val_loss: 1571.1387\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.4633 - val_loss: 1583.5349\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.1240 - val_loss: 1599.8621\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.3633 - val_loss: 1569.4255\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.3611 - val_loss: 1584.2664\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.8662 - val_loss: 1582.8719\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.2434 - val_loss: 1580.9553\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.4883 - val_loss: 1584.3210\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.7582 - val_loss: 1589.1866\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.8815 - val_loss: 1583.2637\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.7141 - val_loss: 1577.1638\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.1135 - val_loss: 1587.1271\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.5424 - val_loss: 1584.6495\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.2976 - val_loss: 1587.9563\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.1931 - val_loss: 1587.3030\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.5690 - val_loss: 1579.9274\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.4084 - val_loss: 1585.8723\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.1840 - val_loss: 1581.5482\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.5061 - val_loss: 1578.6689\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.7312 - val_loss: 1588.2297\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1690.7708 - val_loss: 1576.4485\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.9680 - val_loss: 1585.6801\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.5492 - val_loss: 1583.8971\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.6956 - val_loss: 1579.1556\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.3496 - val_loss: 1585.2937\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.7009 - val_loss: 1591.7832\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.2000 - val_loss: 1582.2122\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1688.4541 - val_loss: 1577.1704\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1688.1758 - val_loss: 1596.4319\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1691.6871 - val_loss: 1583.1840\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.5964 - val_loss: 1580.7231\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.6584 - val_loss: 1575.3092\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.8871 - val_loss: 1580.7733\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.2780 - val_loss: 1576.9890\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1682.9297 - val_loss: 1594.7379\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1681.9008 - val_loss: 1588.7454\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1686.0879 - val_loss: 1574.4772\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1685.7988 - val_loss: 1584.7839\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1684.4365 - val_loss: 1588.2426\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1689.6393 - val_loss: 1577.6981\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.4154 - val_loss: 1583.9240\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1682.9316 - val_loss: 1592.6370\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.3779 - val_loss: 1581.9329\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1684.8796 - val_loss: 1570.7362\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.1031 - val_loss: 1587.0070\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.1217 - val_loss: 1585.1294\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.3650 - val_loss: 1573.1311\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1689.3252 - val_loss: 1597.7965\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1689.4768 - val_loss: 1580.5735\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1683.5906 - val_loss: 1583.6125\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1682.6523 - val_loss: 1582.8821\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1691.7285 - val_loss: 1581.2712\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1688.4899 - val_loss: 1600.8475\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1689.7289 - val_loss: 1573.7402\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1680.8611 - val_loss: 1585.9772\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1687.0515 - val_loss: 1580.0171\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.7767 - val_loss: 1592.2709\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.4528 - val_loss: 1587.7792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5da05d9c00>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2\n",
        "model_2 = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(1,)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='adam', loss='mse')\n",
        "model_2.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "dNKmqDxQJyQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31451cbb-896a-4458-82f7-b1123b4bcfa4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 1710.2008 - val_loss: 1571.2418\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1693.6536 - val_loss: 1586.2383\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1700.0961 - val_loss: 1590.4897\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1689.1057 - val_loss: 1576.6416\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.5631 - val_loss: 1580.6111\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.3440 - val_loss: 1608.0309\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.7832 - val_loss: 1575.7554\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.1791 - val_loss: 1587.0739\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.7764 - val_loss: 1581.0295\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1688.1254 - val_loss: 1593.4651\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.3809 - val_loss: 1574.0237\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.4323 - val_loss: 1586.3634\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1688.7336 - val_loss: 1591.4509\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.0980 - val_loss: 1574.2247\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1690.0580 - val_loss: 1585.9889\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.6941 - val_loss: 1582.3237\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1692.2732 - val_loss: 1580.8573\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.0739 - val_loss: 1584.3158\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.6654 - val_loss: 1581.4131\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.2845 - val_loss: 1583.4659\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.2562 - val_loss: 1583.6193\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.5996 - val_loss: 1582.0161\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.8141 - val_loss: 1580.3701\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.5131 - val_loss: 1583.3588\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.4996 - val_loss: 1593.5156\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.1674 - val_loss: 1581.0527\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.9037 - val_loss: 1578.5146\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.6711 - val_loss: 1588.4950\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.2832 - val_loss: 1580.3295\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1687.4125 - val_loss: 1589.3398\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.4697 - val_loss: 1579.3499\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.9639 - val_loss: 1575.1741\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.6158 - val_loss: 1586.8043\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.7318 - val_loss: 1581.2463\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.0703 - val_loss: 1585.5394\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.3516 - val_loss: 1580.4675\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.5573 - val_loss: 1583.3802\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.3510 - val_loss: 1585.3157\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.5715 - val_loss: 1580.7642\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.7943 - val_loss: 1586.8542\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.5336 - val_loss: 1586.1000\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.5964 - val_loss: 1579.5006\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.3740 - val_loss: 1582.1908\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.3658 - val_loss: 1581.0367\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.8484 - val_loss: 1582.4663\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.6814 - val_loss: 1583.9445\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.4197 - val_loss: 1582.6952\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.5756 - val_loss: 1584.7377\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.2375 - val_loss: 1583.6873\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.1215 - val_loss: 1582.5979\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.5912 - val_loss: 1584.6521\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.7546 - val_loss: 1581.8308\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.6338 - val_loss: 1582.7435\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.8187 - val_loss: 1582.3047\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.6949 - val_loss: 1583.5154\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.6145 - val_loss: 1581.7676\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.5807 - val_loss: 1583.6750\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.2806 - val_loss: 1585.4017\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.7096 - val_loss: 1579.9983\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.6246 - val_loss: 1584.2213\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.7330 - val_loss: 1580.5774\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.9521 - val_loss: 1583.2177\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.6045 - val_loss: 1585.5607\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.2727 - val_loss: 1580.1803\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1688.0941 - val_loss: 1579.9662\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.0798 - val_loss: 1580.3495\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.6989 - val_loss: 1582.5179\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.8444 - val_loss: 1584.2172\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.8240 - val_loss: 1583.0961\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1683.1501 - val_loss: 1579.2031\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.4211 - val_loss: 1582.5791\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1681.2230 - val_loss: 1582.6002\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1684.4320 - val_loss: 1584.3417\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.6344 - val_loss: 1584.8792\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.7854 - val_loss: 1585.3484\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1680.9193 - val_loss: 1581.8073\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.2312 - val_loss: 1584.7747\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1681.8197 - val_loss: 1584.1527\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1681.4225 - val_loss: 1586.4592\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.1166 - val_loss: 1585.1511\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1683.9902 - val_loss: 1585.4767\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1682.8639 - val_loss: 1581.2244\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.0748 - val_loss: 1582.9885\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1680.6438 - val_loss: 1583.8665\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1680.6243 - val_loss: 1583.2150\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1680.9023 - val_loss: 1583.8262\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1680.9783 - val_loss: 1582.5994\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1681.3883 - val_loss: 1581.1267\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1679.9856 - val_loss: 1582.4908\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1679.5664 - val_loss: 1583.4695\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.5297 - val_loss: 1582.8549\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1679.6355 - val_loss: 1583.0248\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.6461 - val_loss: 1583.9670\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.5924 - val_loss: 1583.1407\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.3842 - val_loss: 1583.2773\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1679.7719 - val_loss: 1582.7004\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.2434 - val_loss: 1581.9948\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1679.4968 - val_loss: 1582.3082\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.5681 - val_loss: 1584.6891\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1680.6520 - val_loss: 1583.0647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5da02edf90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 3\n",
        "model_3 = keras.Sequential([\n",
        "    keras.layers.Dense(256, activation='relu', input_shape=(1,)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_3.compile(optimizer='adam', loss='mse')\n",
        "model_3.fit(X_train, Y_train, validation_split=0.2, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "bJpwU6v0JyWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdf45cb-d459-498c-9289-be2bbd9f393c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 10ms/step - loss: 1706.3066 - val_loss: 1586.4253\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1689.6342 - val_loss: 1587.0463\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1693.7328 - val_loss: 1579.0645\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.1035 - val_loss: 1576.5115\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.1135 - val_loss: 1578.7258\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1688.6293 - val_loss: 1589.5300\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1691.3092 - val_loss: 1571.6295\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.4398 - val_loss: 1587.9523\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.0967 - val_loss: 1582.3728\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1691.9795 - val_loss: 1584.8879\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.3096 - val_loss: 1598.4436\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.9766 - val_loss: 1582.3831\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.9459 - val_loss: 1579.0808\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1685.1588 - val_loss: 1588.2607\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.3998 - val_loss: 1580.9902\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1690.7517 - val_loss: 1571.3890\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.8463 - val_loss: 1588.7708\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.0433 - val_loss: 1585.0894\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.1270 - val_loss: 1582.4663\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.3425 - val_loss: 1584.6619\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.9362 - val_loss: 1584.6418\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.7646 - val_loss: 1578.5638\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.6934 - val_loss: 1581.4192\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.6927 - val_loss: 1581.6853\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.8289 - val_loss: 1586.4008\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.9652 - val_loss: 1582.9062\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.6488 - val_loss: 1582.6995\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.4623 - val_loss: 1581.7655\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1687.5238 - val_loss: 1580.4928\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1683.7087 - val_loss: 1590.4641\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.9514 - val_loss: 1585.1489\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.1211 - val_loss: 1576.1199\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1691.1370 - val_loss: 1585.3551\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.2330 - val_loss: 1575.9670\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.9724 - val_loss: 1573.3363\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.7301 - val_loss: 1582.3715\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.8363 - val_loss: 1586.8699\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1684.9373 - val_loss: 1578.0745\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.6360 - val_loss: 1585.2570\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.2979 - val_loss: 1584.7932\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1684.0076 - val_loss: 1583.7440\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1688.9922 - val_loss: 1583.5714\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1685.9275 - val_loss: 1575.4434\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.1035 - val_loss: 1579.8970\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.7698 - val_loss: 1581.2106\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.8783 - val_loss: 1590.0703\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1680.3783 - val_loss: 1576.9591\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1686.1998 - val_loss: 1582.8439\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1686.7585 - val_loss: 1577.3151\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.3660 - val_loss: 1582.3092\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.2527 - val_loss: 1583.8474\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1692.0621 - val_loss: 1594.0833\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.0354 - val_loss: 1572.5333\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1687.4147 - val_loss: 1574.8180\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.3480 - val_loss: 1586.6893\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1685.1267 - val_loss: 1578.7291\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1686.4135 - val_loss: 1589.0312\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1692.3373 - val_loss: 1592.5873\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1701.9695 - val_loss: 1573.3336\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1684.7611 - val_loss: 1579.2455\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1684.6133 - val_loss: 1596.3328\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1688.9033 - val_loss: 1572.9518\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1688.8623 - val_loss: 1594.1198\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1682.2327 - val_loss: 1578.5527\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1685.6715 - val_loss: 1576.8392\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1684.3043 - val_loss: 1589.6609\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1681.5110 - val_loss: 1581.4414\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1685.1136 - val_loss: 1576.7015\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1686.1287 - val_loss: 1592.8949\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1685.0569 - val_loss: 1581.0857\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1682.3031 - val_loss: 1589.7325\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.6052 - val_loss: 1584.7559\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1683.1305 - val_loss: 1572.7433\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1683.0752 - val_loss: 1585.3384\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1682.7949 - val_loss: 1584.8190\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1691.5690 - val_loss: 1576.4868\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1686.9431 - val_loss: 1580.2264\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1682.1106 - val_loss: 1584.1902\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.6168 - val_loss: 1585.0977\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1685.7119 - val_loss: 1579.2109\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1682.0540 - val_loss: 1572.6667\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.9730 - val_loss: 1580.0886\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1689.2822 - val_loss: 1586.0612\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.5140 - val_loss: 1584.1036\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1683.3643 - val_loss: 1572.3334\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.4783 - val_loss: 1581.7800\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1681.1838 - val_loss: 1592.0591\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1686.8767 - val_loss: 1577.3668\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1682.4343 - val_loss: 1587.9963\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.8109 - val_loss: 1583.3347\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1682.7136 - val_loss: 1572.0100\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1684.0699 - val_loss: 1579.5377\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.9844 - val_loss: 1584.5883\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1681.8405 - val_loss: 1585.5637\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1679.9733 - val_loss: 1575.6526\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.1492 - val_loss: 1577.5319\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1681.7292 - val_loss: 1585.5632\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1685.8431 - val_loss: 1580.2589\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1689.0774 - val_loss: 1588.4725\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1685.7539 - val_loss: 1577.2336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5d93f9ee60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3 model evaluation\n",
        "\n",
        "In the cells below, eval your model with training data, test data ( with model.evaluate( ) ), and plot your predict result on the same plot with the plot of goal function."
      ],
      "metadata": {
        "id": "pzJ2ZNGKJ9oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 1 Test Loss:\", model_1.evaluate(X_test, Y_test))\n",
        "print(\"Model 2 Test Loss:\", model_2.evaluate(X_test, Y_test))\n",
        "print(\"Model 3 Test Loss:\", model_3.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "id": "MCHdT5BxNMnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff969e8-d8aa-417c-cb66-e99a24d013f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 3ms/step - loss: 1727.4719\n",
            "Model 1 Test Loss: 1727.471923828125\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1730.8884\n",
            "Model 2 Test Loss: 1730.888427734375\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1736.7686\n",
            "Model 3 Test Loss: 1736.7685546875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 4 get model output and feedforward by yourself\n",
        "\n",
        "Recall how a Feedforward Neural Network gets its output. Now choose your model with highest accuracy, and call get_weights( ) to get its weights and bias.\n",
        "<br> Hint: bias and weights have different dimensions in most cases. Try to guess which index represent bias before you look it up on the internet.\n",
        "\n",
        "<br> Afterwards, choose 5 data from your training dataset, do all the necessary calculations (with program of course), and get the output of your model. Compare it to the model.predict( ) result.\n",
        "<br> They should be identical for the first several digitals, if not for all digits."
      ],
      "metadata": {
        "id": "t3XlrMjvNPIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_hidden = np.array([[0.5]])  # Shape: (1, 1) for 1 input feature to 1 hidden neuron\n",
        "bias_hidden = np.array([0.1])  # Shape: (1,) for 1 hidden neuron\n",
        "weights_output = np.array([[0.7]])  # Shape: (1, 1) for 1 hidden neuron to 1 output neuron\n",
        "bias_output = np.array([0.05])  # Shape: (1,) for the output neuron\n",
        "\n",
        "# Sample input data (5 data points)\n",
        "X_sample = np.array([[0.1], [0.2], [25], [0.4], [0.5]])\n",
        "\n",
        "# ReLU activation function\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Hidden layer\n",
        "hidden_layer_input = np.dot(X_sample, weights_hidden) + bias_hidden\n",
        "hidden_layer_output = relu(hidden_layer_input)\n",
        "\n",
        "# Output layer\n",
        "output_layer_input = np.dot(hidden_layer_output, weights_output) + bias_output\n",
        "\n",
        "print(\"Manual output calculations:\\n\", output_layer_input)"
      ],
      "metadata": {
        "id": "QlJCicHTOndf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b2385e-1319-4749-d307-30ffb87957de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual output calculations:\n",
            " [[0.155]\n",
            " [0.19 ]\n",
            " [8.87 ]\n",
            " [0.26 ]\n",
            " [0.295]]\n"
          ]
        }
      ]
    }
  ]
}